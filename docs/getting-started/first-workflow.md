# Premier workflow

Ce guide vous accompagne dans la crÃ©ation et l'exÃ©cution de votre premier workflow d'agents.

## Workflow simple : Echo Bot

CommenÃ§ons par un workflow minimal qui transforme une entrÃ©e utilisateur.

### 1. DÃ©finition JSON

CrÃ©ez un fichier `my_first_workflow.json` :

```json
{
  "name": "Echo Workflow",
  "description": "Mon premier workflow qui reformule l'entrÃ©e utilisateur",
  "start_node": "echo_agent",
  "nodes": [
    {
      "id": "echo_agent",
      "name": "Echo Agent",
      "type": "process",
      "agent_config": {
        "type": "pydantic",
        "model": "openai:gpt-4o-mini",
        "name": "EchoBot",
        "system_prompt": "You are a friendly assistant. Rephrase the user's message in a more formal and structured way."
      }
    },
    {
      "id": "end",
      "name": "End",
      "type": "end",
      "agent_config": {}
    }
  ],
  "edges": [
    {"from_node": "echo_agent", "to_node": "end"}
  ]
}
```

### 2. Code d'exÃ©cution

CrÃ©ez un fichier `run_my_workflow.py` :

```python
import asyncio
import json
from src.application.services import WorkflowService

async def main():
    # Charger le workflow
    with open("my_first_workflow.json", "r") as f:
        workflow_json = json.load(f)
    
    # CrÃ©er le service
    workflow_service = WorkflowService()
    
    # DonnÃ©es d'entrÃ©e
    input_data = "salut, comment Ã§a va ?"
    
    # ExÃ©cuter le workflow
    result = await workflow_service.execute_workflow_from_json(
        workflow_json,
        input_data
    )
    
    print("ğŸ RÃ©sultat :")
    print(result['final_result'])
    
    print(f"\nğŸ“Š Statistiques :")
    print(f"Ã‰tapes : {len(result['execution_history'])}")
    print(f"ItÃ©rations : {result['total_iterations']}")

if __name__ == "__main__":
    asyncio.run(main())
```

### 3. ExÃ©cution

```bash
uv run run_my_workflow.py
```

**RÃ©sultat attendu :**
```
ğŸ RÃ©sultat :
Bonjour ! Je me porte bien, merci de vous en enquÃ©rir. Comment puis-je vous assister aujourd'hui ?

ğŸ“Š Statistiques :
Ã‰tapes : 2
ItÃ©rations : 2
```

## Workflow avec dÃ©cision : Sentiment Analyzer

CrÃ©ons maintenant un workflow qui prend des dÃ©cisions.

### 1. DÃ©finition JSON

```json
{
  "name": "Sentiment Analysis Workflow",
  "description": "Analyse le sentiment et route vers la rÃ©ponse appropriÃ©e",
  "start_node": "sentiment_analyzer",
  "nodes": [
    {
      "id": "sentiment_analyzer",
      "name": "Sentiment Analyzer",
      "type": "decision",
      "agent_config": {
        "type": "pydantic",
        "model": "openai:gpt-4o-mini",
        "name": "SentimentAnalyzer",
        "node_type": "decision",
        "system_prompt": "Analyze the sentiment of the text and return JSON: {\"positive\": true/false, \"confidence\": 0.0-1.0, \"emotion\": \"joy|anger|sadness|neutral\"}"
      }
    },
    {
      "id": "positive_responder",
      "name": "Positive Responder",
      "type": "process",
      "agent_config": {
        "type": "pydantic",
        "model": "openai:gpt-4o-mini",
        "name": "PositiveResponder",
        "system_prompt": "Generate an enthusiastic and supportive response to positive sentiment."
      }
    },
    {
      "id": "negative_responder",
      "name": "Negative Responder", 
      "type": "process",
      "agent_config": {
        "type": "pydantic",
        "model": "openai:gpt-4o-mini",
        "name": "NegativeResponder",
        "system_prompt": "Generate an empathetic and helpful response to negative sentiment."
      }
    },
    {
      "id": "end",
      "name": "End",
      "type": "end",
      "agent_config": {}
    }
  ],
  "edges": [
    {"from_node": "sentiment_analyzer", "to_node": "positive_responder", "condition": "positive"},
    {"from_node": "sentiment_analyzer", "to_node": "negative_responder", "condition": "negative"},
    {"from_node": "positive_responder", "to_node": "end"},
    {"from_node": "negative_responder", "to_node": "end"}
  ]
}
```

### 2. Mise Ã  jour de l'Ã©valuateur

Ajoutez la condition `negative` dans `ConditionEvaluator` :

```python
# Dans src/core/condition_evaluator.py
def _evaluate_generic_condition(self, condition: str, result: Dict[str, Any], context: Dict[str, Any]) -> bool:
    # ... code existant ...
    
    # Conditions nÃ©gatives
    negative_mappings = {
        "rejected": "approved",
        "failed": "passed", 
        "not_hired": "hired",
        "incomplete": "complete",
        "negative": "positive"  # Nouvelle condition
    }
```

### 3. Test du workflow

```python
import asyncio
import json
from src.application.services import WorkflowService

async def test_sentiment_workflow():
    with open("sentiment_workflow.json", "r") as f:
        workflow_json = json.load(f)
    
    workflow_service = WorkflowService()
    
    test_cases = [
        "Je suis tellement heureux aujourd'hui !",
        "Je me sens vraiment dÃ©primÃ©...",
        "C'est une journÃ©e normale."
    ]
    
    for text in test_cases:
        print(f"\nğŸ§ª Test: '{text}'")
        result = await workflow_service.execute_workflow_from_json(workflow_json, text)
        print(f"â¡ï¸ RÃ©ponse: {result['final_result']}")

if __name__ == "__main__":
    asyncio.run(test_sentiment_workflow())
```

## Workflow avec boucle : Auto-amÃ©lioration

CrÃ©ons un workflow qui s'amÃ©liore en boucle.

### 1. DÃ©finition JSON

```json
{
  "name": "Self-Improving Content",
  "description": "GÃ©nÃ¨re et amÃ©liore du contenu en boucle",
  "start_node": "content_generator",
  "nodes": [
    {
      "id": "content_generator",
      "name": "Content Generator",
      "type": "process",
      "max_iterations": 3,
      "agent_config": {
        "type": "pydantic",
        "model": "openai:gpt-4o-mini",
        "name": "ContentGenerator",
        "system_prompt": "Generate or improve content based on input. If you receive feedback, incorporate it to make the content better."
      }
    },
    {
      "id": "quality_checker",
      "name": "Quality Checker",
      "type": "decision",
      "max_iterations": 3,
      "agent_config": {
        "type": "pydantic",
        "model": "openai:gpt-4o-mini",
        "name": "QualityChecker",
        "node_type": "decision",
        "system_prompt": "Evaluate content quality and return JSON: {\"approved\": true/false, \"score\": 0-100, \"feedback\": \"specific improvements needed\", \"final_review\": false}"
      }
    },
    {
      "id": "end",
      "name": "End",
      "type": "end",
      "agent_config": {}
    }
  ],
  "edges": [
    {"from_node": "content_generator", "to_node": "quality_checker"},
    {"from_node": "quality_checker", "to_node": "content_generator", "condition": "rejected_not_final"},
    {"from_node": "quality_checker", "to_node": "end", "condition": "approved"},
    {"from_node": "quality_checker", "to_node": "end", "condition": "final_review"}
  ]
}
```

## Bonnes pratiques pour dÃ©buter

### 1. Commencez simple

```json
// âœ… Bon premier workflow
{
  "nodes": [
    {"id": "single_agent", "type": "process", ...},
    {"id": "end", "type": "end", ...}
  ],
  "edges": [
    {"from_node": "single_agent", "to_node": "end"}
  ]
}

// âŒ Ã‰vitez la complexitÃ© initiale
{
  "nodes": [...10 agents avec boucles complexes...]
}
```

### 2. Testez chaque Ã©tape

```python
# Test d'un agent isolÃ©
async def test_single_agent():
    agent_config = {
        "type": "pydantic",
        "model": "openai:gpt-4o-mini",
        "system_prompt": "..."
    }
    
    agent = PydanticAgent(agent_config)
    result = await agent.execute("test input", {})
    print(f"Agent result: {result}")
```

### 3. VÃ©rifiez les formats JSON

```python
# Pour les agents de dÃ©cision
def validate_decision_output(result):
    if not isinstance(result, dict):
        raise ValueError("Decision agents must return dict")
    
    required_fields = ["approved"]  # ou "passed", "valid", etc.
    for field in required_fields:
        if field not in result:
            raise ValueError(f"Missing required field: {field}")
```

### 4. Utilisez des prompts clairs

```json
// âœ… Bon prompt
{
  "system_prompt": "You are a content reviewer. Evaluate the content for clarity (40%), accuracy (30%), and engagement (30%). Return JSON: {\"approved\": true/false, \"score\": 0-100, \"feedback\": \"specific feedback\"}. Approve only if score >= 80."
}

// âŒ Prompt vague
{
  "system_prompt": "Review this content."
}
```

## DÃ©bogage courant

### Agent ne rÃ©pond pas

```bash
# VÃ©rifiez les variables d'environnement
echo $OPENAI_API_KEY

# Testez la connexion API
python -c "from openai import OpenAI; client = OpenAI(); print('API OK')"
```

### JSON invalide

```python
# Validez votre JSON
import json

try:
    with open("workflow.json") as f:
        workflow = json.load(f)
    print("JSON valide âœ…")
except json.JSONDecodeError as e:
    print(f"JSON invalide âŒ: {e}")
```

### Conditions ne fonctionnent pas

```python
# VÃ©rifiez le format de sortie des agents de dÃ©cision
result = await agent.execute(input_data, context)
print(f"Agent output type: {type(result)}")
print(f"Agent output: {result}")

# Doit Ãªtre un dict pour les agents de dÃ©cision
assert isinstance(result, dict), "Decision agents must return dict"
```

## Prochaines Ã©tapes

Une fois ces premiers workflows maÃ®trisÃ©s :

1. ğŸ”„ [Explorez les workflows complexes](../examples/writer-reviewer.md)
2. ğŸ¯ [Apprenez les conditions avancÃ©es](../workflow-definition/conditions.md)
3. ğŸ“Š [Comprenez l'Ã©change de donnÃ©es](../workflow-definition/data-flow.md)
4. ğŸ—ï¸ [DÃ©couvrez l'architecture](../architecture/overview.md)
